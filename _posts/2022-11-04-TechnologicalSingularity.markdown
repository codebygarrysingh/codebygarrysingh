---
layout: post
title:  "What is Technological Singularity? Why should you be worried about AI?"
date:   2023-11-04
categories: 
  - "Artificial Intelligence"
  - "AI Regulation"
author: Garry Singh
---
<div class="summary">
     <span class="fas fa-robot icon"><b> In the Brief</b></span>
  <p>
    Elon Musk and Rishi Sunak concluded the 2023 AI Safety Summit by discussing the potential threats to the labor market as progress in AI intensifies. Musk highlighted his concerns regarding the dangers of AI and the need for support for the growing developments in AI. The concept of Technological Singularity is a point in the future when AI surpasses the minimum threshold required to sustain itself, leading to an ultimate explosion of an unprecedented, self-growing piece of software that stretches far beyond human intelligence. The advancement of AI is starting to eclipse our own and this shift is monumental. The question is when this will happen and what the consequences will be.
  </p>
</div>
<br>
As the <a href="https://www.gov.uk/government/topical-events/ai-safety-summit-2023" target="_blank">2023 AI Safety Summit</a> concluded, the conversation between Rishi Sunak and Elon Musk remained a key highlight as they discussed potential threats to the labor market with progress in AI intensifying.

**Elon Musk's Concern**

While the conversation revolved around the topic of jobs and their impact on the labor market, Elon Musk had a strong intent to highlight concerns regarding support for the growing developments in AI. His warning isn't just another voice in the crowd; this statement about the dangers of AI coming from one of the most successful tech entrepreneurs of all time must hold deeper significance.

This is not the first time that <a href="https://www.theguardian.com/technology/2023/apr/03/the-danger-of-blindly-embracing-the-rise-of-ai">the potential dangers</a> of developments in Generalized AI, or an AI smarter than any conscious human, have garnered attention. The discussions surrounding the ethical, social, and existential implications of achieving such advanced AI capabilities have been ongoing for years, and leaders in the tech industry, like Elon Musk, play a pivotal role in raising awareness about these critical issues.

**What is Technological Singularity?**

The concept of Technological Singularity resonates with the singularity of the Universe in the cosmological dictionary, just before the ultimate Big Bang took place. As Stephen Hawking puts it, our universe is ever-expanding, showing no signs of enclosed boundaries. 

Similarly, <a href="https://en.wikipedia.org/wiki/Technological_singularity" target="_blank">technological singularity</a> is a point in the future when AI surpasses the minimum threshold required to sustain itself, leading to an ultimate explosion of an unprecedented, self-growing piece of software that stretches far beyond human intelligence on the spectrum, surpassing even the smartest humans to have ever existed.


**Why should you be worried?**

This '<a href="https://en.wikipedia.org/wiki/Superintelligence" target="_blank">Superintelligence</a>,' as it's often dubbed, isn't just going to tinker with our job market. It's set to reshape our world in ways we can barely fathom. The potential loss of jobs is just the tip of the iceberg, overshadowed by the looming existential crisis that could follow.

To truly grasp this, you need to dive into the rapid advancement of AI. We're now in an era where AI's capabilities are starting to eclipse our own. This shift is monumental and fundamentally changes the way we look at the world.

The question isn't whether this will happen, but when. And that 'when' is what keeps tech visionaries, like Elon Musk, up at night. The discussions about this topic, like the one <a href="https://www.theguardian.com/technology/2023/nov/03/rishi-sunak-elon-musk-ai-summit-what-we-learned" target="_blank">between Musk and Sunak</a>, prompt us to address critical questions. Can we wield the power of AI for our benefit without surrendering control to an intelligence that may outstrip our own? Are we prepared for the uncharted territory that lies ahead?

To explore these questions, we don't need a deep dive into complex theories and jargon. We just need to venture into the world of philosophy, science, and ethics where the curiosity and concerns of everyday people intersect. This is where we start to fathom the profound journey ahead, one that could redefine our existence and test the limits of our understanding.

**Are we there yet?**

We are still far from replicating human concious level intelligence. There have been significant advancements in Generative AI, Vision and Speech AI. Most of the applications of AI are currently limited to domain level expertise and we are still farther away from more Generalized AI. 

There have been numerous experiments and developments in fields of cognitive replications or <a href="https://openworm.org/" target="_blank">digital twins modeled from real neural network in smallest microorganisms like C. Elegans</a>. Another relevant examples including enhanced brain cognition with insertions of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4304489/" target="_blank">neural conductors in brain</a>. Advancements in Genetic mutations and enhancements have also raised eyebrows from many experts vowing for ethical use of technology. 

There have been significant push in recent years to adopt <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper" target="_blank">pro-innovation approach</a> while laying out concrete regulation and compliance frameworks. Its just matter of time when we stil start realizing importance of mandating these regulations to track progress on projects advancing rapidly in field of AI. 

